### Open Voice Network Privacy & Security Work Group
### Working Document
As developed by the Privacy & Security Work Group of the Open Voice Network Technical Committee for review by the Technical Committee, for the purpose of 
* advancing the OVN Technical Commmittee MasterPlan
* guiding OVN Technical Committee discussions in re: privacy and security
* guiding OVN Technical Committee decisions

### Privacy and Security Work Group Remit
The remit of the Privacy and Security Work Group of the Technical Advisory Committee of the Open Voice Network is to *identify, define, and prioritize the capabilities that the OVN must "design in" in regards to individual privacy and security.*  
### Deliverable Date
The Privacy and Security Work Group is expected to present a report to the Technical Advisory Committee in its meeting of 30 October 2020.

### The World For Which We Work
By 2025, conversational AI will be a primacy interface to the connected digital world of content, enterprises, things, and persons.  It will be accessed and used through multiple assistants, multiple platforms, and nearly all digital devices.
### Problem Statement per meeting 2020.07.01
Draft Privacy and Security Working Group Problem Statement: *Voice Technology has the power to change our lives, however with voice technology comes a new set of privacy and security risks and concerns that are inherently linked with the adoption and trust of the technology. The goal is to identify and extend existing open privacy and security standards, and guidance with detail specific to voice technologies.*
### Statement of Consolidated Values, Technical Capabilities, and Standards to Address Voice-Specific Privacy Risks
A draft statement presented to the Technical Advisory Committee on 2020.10.02.
*At the heart of voice-specific privacy is **data ownership**, which may be defined on four related vectors: the **collection** of data, the **control** of collected data and its use, the **consent** with which data is shared, and the **clarity**or transparency of collection, control, and consent processes. Here are eight recommendations of voice-specific issues for design-in consideration by the Open Voice Network.*
#### 1.  CONSENT FOR DATA COLLECTION. 
Data subjects must be allowed to give explicit, unambiguous consent before the collection and processing of personal data.
Illustrative example: XXX
Technical implication: YYY
#### 2. LIMITED COLLECTION 
Collected raw data should be securely deleted immediately post-processing.
Illustrative example: XXX
Technical implication:  YYY
#### 3. CONTROL  
Any data that is not deleted should be accessible by the consumer with the ability to review, correct, or securely delete their data.
Illustrative example: XXX
Technical implication:  YYY
#### 4.  TRANSPARENCY
A voice user-interface should be made easily accessible and readily available to the consumer for the purpose of providing user notification of general data processing and algorithmic inference routines.
Illustrative example: XXX
Technical implication:  YYYU
#### 5. TRANSPARENCY
A voice user-interface should be made easily accessible and readily available to the consumer for the purpose of providing user notification of general data processing and algorithmic inference routines. 
Illustrative example:  XXX
Technical implication:  YYY
#### 6. CONSENT
A voice user-interface should be made easily accessible and readily available to the consumer for the purpose of accepting explicit consent for data collection, usage, and sharing policies.
Illustrative example:  XXX
Technical implication:  YYY.
#### 7.  CONSENT
Data should be only be collected or used by consenting parties.
Illustrative example:  XXX
Technical implication:  YYY.
#### 8. CONTROL
Voice confirmation and playback routines should only include information provided in related rrequest; if additional information is necessary, explicit prompting and explicit affirmation should occur before confirmation and playback of this information.
Illustrative example:  XXX
Technical implication:  YYY. 

### Problem Statements Unique to Voice in re: Privacy
- the claiming by proprietary platforms of all personal and commercial data communicated through said platforms
- absence of workable guidelines and regulations as to the 1) content-based sharing of voice data, including biometric and biomarker data, and 2) enterprise ethical use and security of personal, biometric, and biomarker data.
- Other key points to discuss and integrate:
WRT Privacy and Security, what makes voice different?
- Its always listening
- Its subjective
- It involves biometrics
- Commercial vs. Private viewpoints
- Data ownership and data sharing
### Aspirational Requirements: Privacy
Per meeting of 2020.07.21
A construct based upon high-level data definitions: 
- Level 0 - passive stage (always listening) Transparency and consent of listening in "non-active" state 
- Level  1 - basic (wake word/invocation?)
- Level 2 - contextual (location, language, identifies user, background noise) PII
- Level 3 - personalization (my preferences, history) PII
- Level 4 - application -- invoking a third party (Macy's) ISSUE: 3rd party processing data / hosting entity  (begin to tackle ownership and use rights) 
- Level 5 - in the application (commercial data - payment, account, transaction)(ownership and use rights)
- Level 6 - emotional/sentiment 
Evaluated in a matrix with key variables of transparency, consent, ownership, use, (and trust, and the data itself)  across each stage 
- PII, biomarkers exist in all stages
* question from J. Larson: regarding the transactional reality of data; when/not confirmed?
* question from M. Frazzini: what of transparency as a key variable?  I must know what is being collected in order to give consent. A precursor of consent.
* comment from S. Prayaga: importance of trust -- in partners, in processes
* J. Larson: add "conditions" for moving between stages to the description of each stage

Per meeting of 2020.07.14, issues for consideration -- for further discussion :
- consent, which includes the issue of awareness
- ownership, which includes user control and sharing
- use, which may include ownership, cointrol, and sharing
- control 
What do we seek to achieve in addition to the privacy guidelines/regulations of NIST, GDPR, CCPA, the Vatican, etc.?  Proposed:
- transparent, readily-available, consent-based opportunity for direct, unfiltered connection between entities
- transparent, readily-available, consent-based opportunity for data sharing, including biometric and biomarker data
- transparency of data collection and analysis process and intent




